# -*- coding: utf-8 -*-
"""Proyek_Model_Sistem_ Rekomendasi_Google_Play _Store_Apps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tXOZpmeG9v0W0XzM0n50qh_H-zOL9aSB

# **1. Perkenalan Dataset**

Dataset yang digunakan dalam proyek ini adalah Google Play Store Apps, yang diperoleh dari Kaggle. Dataset ini terdiri dari 2312944 baris dan 24 kolom, mencakup kombinasi fitur numerik dan kategorikal. Tujuan dari proyek ini adalah memberikan rekomendasi aplikasi yang ada di play store kepada pengguna

# **2. Import Library**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import ConfusionMatrixDisplay

from google.colab import files

"""Pada tahap ini, mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.

# **3. Memuat Dataset**
"""

files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d gauthamp10/google-playstore-apps
!unzip google-playstore-apps.zip

data = pd.read_csv('/content/Google-Playstore.csv')
data

"""Pada tahap ini, memuat dataset ke dalam notebook. Saya menggunakan pustaka pandas untuk membacanya karrena dataset saya dalam format CSV . Disini juga saya mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.

karena data saya di ambil langsung dari kaggle, jadi saya sebelumnya sudah menghubungkan Colab ke kaggle terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.

# **4. Data Preprocessing**
"""

selected_columns = [
    'App Name',
    'App Id',
    'Category',
    'Rating',
    'Rating Count',
    'Installs',
    'Price',
    'Free',
    'Size',
    'Minimum Android',
    'Content Rating'
]

data_selected = data[selected_columns]

"""Untuk membangun model sistem rekomendasi, saya hanya memerlukan beberapa kolom yang relevan. Oleh karena itu, saya membuat variabel baru yang hanya berisi kolom-kolom berikut: 'App Name', 'App Id', 'Category', 'Rating', 'Rating Count', 'Installs', 'Price', 'Free', 'Size', 'Minimum Android', dan 'Content Rating'. Pemilihan kolom ini didasarkan pada pertimbangan bahwa informasi tersebut penting untuk menghasilkan rekomendasi yang akurat dan sesuai dengan kebutuhan pengguna.


"""

data_selected

"""jadi data yang akan di pakai itu memiliki
- 2.312.944 baris
- 11 kolom


"""

import matplotlib.pyplot as plt
plt.rcParams['font.family'] = 'DejaVu Sans'  # Ganti font default

data_selected.hist(bins=50, figsize=(20,15))
plt.show()

"""###Histogram

- Rating: Terlihat mayoritas nilai Rating berkisar di antara 4 dan 5, artinya sebagian besar aplikasi mendapatkan penilaian bagus.

- Rating Count: Distribusinya sangat condong ke kiri (right-skewed), sebagian besar aplikasi hanya memiliki sedikit rating.

- Price: Hampir semua aplikasi gratis (harga = 0), hanya sebagian kecil yang memiliki harga tinggi, dan ini menunjukkan adanya outlier.
"""

sns.pairplot(data_selected, diag_kind = 'kde')

"""###Pairplot
- airplot menunjukkan hubungan antar fitur numerik secara visual.

- Hampir semua kombinasi fitur memiliki pola menyebar luas (tidak linear), dengan beberapa titik ekstrem (outlier).

- Rating vs Rating Count menunjukkan bahwa meski banyak aplikasi dengan rating bagus, tidak semua mendapat banyak ulasan.

- Price vs fitur lain terlihat tidak memiliki hubungan yang kuat dan dipenuhi nilai nol.
"""

# Menentukan kolom numerik dan kategorikal
categorical_cols = data_selected.select_dtypes(include=['object']).columns
numerical_cols = data_selected.select_dtypes(include=['int64', 'float64']).columns

plt.figure(figsize=(10, 8))
correlation_matrix = data_selected[numerical_cols].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""###Correlation Matrix (Heatmap)
- Korelasi antar fitur sangat lemah:

    a. Rating vs Rating Count: 0.01 (hampir tidak ada korelasi)

    b. Rating vs Price: -0.00 (sangat lemah negatif)

    c. Rating Count vs Price: -0.00 juga.

- Artinya, fitur-fitur numerik ini tidak saling bergantung secara linear, dan bisa dianggap sebagai fitur independen dalam model sederhana.

- Ini juga memberi sinyal bahwa kamu perlu teknik feature engineering atau transformasi lain jika ingin membangun model yang lebih baik.

# **5. Data Preparation**
"""

jumlah_nol = (data_selected['Rating'] == 0).sum()
print("Jumlah nilai 0 di kolom Rating:", jumlah_nol)

jumlah_nol = (data_selected['Rating Count'] == 0).sum()
print("Jumlah nilai 0 di kolom Rating Count:", jumlah_nol)

"""Dapat dilihat bahwa pada kolom Rating dan Rating Count terdapat data yang bernilai 0. Padahal, secara logika, kolom tersebut seharusnya tidak mengandung nilai 0 karena aplikasi yang memiliki rating pasti memiliki minimal satu ulasan."""

data_selected = data_selected[data_selected['Rating'] != 0]
data_selected = data_selected[data_selected['Rating Count'] != 0]

"""Oleh karena itu, data dengan nilai 0 pada kolom Rating dan Rating Count perlu dihapus agar tidak memengaruhi hasil analisis dan proses pembangunan model rekomendasi.


"""

data.info()

data_selected.info()

"""Dataset yang digunakan terdiri dari 1.253.182 baris dan 11 kolom. Berikut ini adalah nama kolom beserta tipe data masing-masing:

App Name : object

App Id : object

Category : object

Rating : float64

Rating Count : float64

Installs : object

Price : float64

Free : bool

Size : object

Minimum Android : object

Content Rating : object

Secara keseluruhan, terdapat 7 kolom bertipe data object, 3 kolom bertipe float64, dan 1 kolom bertipe bool.
"""

# Identifikasi data yang hilang
missing_data = data_selected.isnull().sum()

# Tampilkan jumlah data yang hilang di setiap kolom
print("Jumlah Data yang Hilang di Setiap Kolom:")
print(missing_data)

"""Terdapat enam kolom dalam dataset yang memiliki data kosong (missing value), yaitu:

App Name : 5 data kosong

Rating : 22.883 data kosong

Rating Count : 22.883 data kosong

Installs : 107 data kosong

Size : 196 data kosong

Minimum Android : 2.499 data kosong
"""

data_selected = data_selected.dropna(subset=['App Name'])
data_selected = data_selected.dropna(subset=['Rating'])
data_selected = data_selected.dropna(subset=['Rating Count'])
data_selected = data_selected.dropna(subset=['Size'])
data_selected = data_selected.dropna(subset=['Minimum Android'])

"""Untuk mengatasi hal tersebut, dilakukan penanganan dengan menghapus baris-baris yang mengandung nilai kosong pada kolom-kolom tersebut. Langkah ini diambil untuk memastikan kualitas data tetap baik sebelum dilakukan analisis lebih lanjut dan pembangunan model sistem rekomendasi."""

# Identifikasi data yang hilang
missing_data = data_selected.isnull().sum()

# Tampilkan jumlah data yang hilang di setiap kolom
print("Jumlah Data yang Hilang di Setiap Kolom:")
print(missing_data)

"""Dilakukan pengecekan ulang untuk memastikan sudah tidak ada lagi kolom yang memiliki nilai kosong"""

print("Jumlah duplikasi: ", data_selected.duplicated().sum())

"""Pengecekan Data yang duplikasi dan ternyata data nya tidak memiliki duplikasi"""

data_selected.describe()

"""Berdasarkan hasil statistik deskriptif, berikut adalah ringkasan dari tiga kolom numerik utama pada dataset:

Rating memiliki rata-rata sebesar 4.12 dengan nilai minimum 2.6 dan maksimum 5.0. Nilai tengah (median) berada di 4.2, yang menunjukkan bahwa sebagian besar aplikasi memiliki rating yang cukup tinggi.

Rating Count menunjukkan jumlah rata-rata ulasan sebesar 121.82, dengan nilai minimum 5 dan maksimum 427. Sebagian besar aplikasi memiliki jumlah ulasan yang relatif sedikit, seperti terlihat dari nilai kuartil ke-1 (Q1) sebesar 12 dan kuartil ke-3 (Q3) sebesar 178.

Price memiliki nilai rata-rata sebesar 0.093, yang menunjukkan bahwa mayoritas aplikasi di Play Store adalah aplikasi gratis (terlihat juga dari nilai median dan kuartil 25%, 50%, dan 75% yang semuanya bernilai 0.0). Harga tertinggi yang tercatat adalah 399.99, menunjukkan adanya beberapa aplikasi berbayar dengan harga premium.


"""

# Pilih semua kolom numerik
num_cols = data_selected.select_dtypes(include=['int64', 'float64']).columns

for feature in num_cols:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=data_selected[feature])
    plt.title(f'Box Plot of {feature}')
    plt.show()

"""Terdapat 3 kolom yang terdeteksi outlier Rating, Rating Count dan Price"""

# Hanya menangani outlier pada kolom tertentu
outlier_cols = ['Rating', 'Rating Count']

for feature in outlier_cols:
    if feature in data_selected.columns:
        Q1 = data_selected[feature].quantile(0.25)
        Q3 = data_selected[feature].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Winsorizing (Mengganti outlier dengan batas bawah/atas)
        data_selected[feature] = np.where(data_selected[feature] < lower_bound, lower_bound, data_selected[feature])
        data_selected[feature] = np.where(data_selected[feature] > upper_bound, upper_bound, data_selected[feature])


data_selected.shape

"""Penanganan outlier dilakukan pada dua kolom, yaitu Rating dan Rating Count Sedangkan untuk kolom Price tidak dialakukan penanganan karena menurut saya kurang tepet saja kalau kolom price tersebut harus ditangani. Metode yang digunakan adalah pendekatan IQR (Interquartile Range), di mana nilai-nilai ekstrem yang berada di luar batas bawah (Q1 - 1.5 * IQR) dan batas atas (Q3 + 1.5 * IQR) dianggap sebagai outlier.

Untuk menangani outlier tersebut, digunakan teknik winsorizing, yaitu mengganti nilai-nilai di bawah batas bawah dengan nilai batas bawah, dan nilai-nilai di atas batas atas dengan nilai batas atas. Hal ini dilakukan untuk mengurangi pengaruh ekstrem pada distribusi data tanpa menghapus baris-baris tersebut.

Setelah proses ini dilakukan, bentuk data tetap utuh, dan tidak ada baris yang dihapus. Langkah ini penting agar model rekomendasi tidak bias akibat adanya nilai yang terlalu ekstrem.
"""

# Cek hasil setelah penanganan outlier

data_selected.describe()

"""Dilakukan pengecekan ulang statistik setelah penanganan outlier"""

# Pilih semua kolom numerik
num_cols = data_selected.select_dtypes(include=['int64', 'float64']).columns

for feature in num_cols:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=data_selected[feature])
    plt.title(f'Box Plot of {feature}')
    plt.show()

"""Dilakukan pengecekan Outlier lagi dan berhasil untuk kolom Rating dan Rating count tidak memilki outlier lagi"""

data_selected.info()

data_selected = data_selected.sample(n=10000, random_state=42)

"""Karena jumlah dataset yang saya gunakan sangat besar dan keterbatasan sumber daya komputasi yang tersedia, maka saya mengambil sampel sebanyak 10.000 data secara acak (random sampling) dari keseluruhan dataset. Langkah ini dilakukan agar proses analisis dan pembangunan model dapat berjalan lebih efisien tanpa mengurangi representasi data secara signifikan.

##**TF-IDF Vectorizer**
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data cuisine
tf.fit(data_selected ['Category'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""Dataset ini mengandung berbagai kategori aplikasi yang beragam, seperti action, adventure, education, finance, health, music, productivity, shopping, sports, dan masih banyak lagi. Kategori-kategori ini mewakili jenis aplikasi yang ada di Google Play Store, mulai dari game, hiburan, pendidikan, hingga utilitas sehari-hari. Keberagaman kategori ini penting untuk membangun sistem rekomendasi yang mampu memahami preferensi pengguna berdasarkan jenis aplikasi yang diminati."""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data_selected ['Category'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

tfidf_matrix.todense()

"""Hasil ini menunjukkan matriks yang merepresentasikan bobot atau nilai pada fitur tertentu dalam data, di mana sebagian besar elemen bernilai nol dan beberapa memiliki nilai non-nol seperti 0.5773. Matriks ini biasanya merupakan output dari proses transformasi fitur, seperti TF-IDF, yang mengukur kepentingan kata atau kategori dalam data teks untuk analisis lebih lanjut."""



import pandas as pd

# Membuat DataFrame dari matriks TF-IDF
tfidf_df = pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data_selected['App Name']
)

# Mengambil 10 sampel baris dan 22 sampel kolom secara acak
tfidf_df.sample(n=10, axis=0).sample(n=61, axis=1)

"""Tabel ini menunjukkan representasi fitur kategori untuk masing-masing aplikasi berdasarkan nama aplikasinya. Setiap kolom mewakili kategori tertentu seperti 'simulation', 'maps', 'personalization', dan lain-lain. Nilai dalam tabel adalah bobot atau skor yang menunjukkan sejauh mana sebuah aplikasi berhubungan dengan kategori tersebut. Sebagian besar nilai bernilai nol, menandakan tidak adanya keterkaitan, sedangkan nilai non-nol, sedangkan kalau ada 0.707 atau 1.0, menunjukkan hubungan yang lebih kuat dengan kategori tersebut.

##**Cosine Similarity**
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Kode ini menggunakan fungsi cosine_similarity dari scikit-learn untuk menghitung kemiripan antar aplikasi berdasarkan matriks TF-IDF yang telah dibuat sebelumnya. Matriks cosine similarity yang dihasilkan adalah matriks persegi dengan ukuran sama seperti jumlah aplikasi, di mana setiap nilai menunjukkan tingkat kemiripan antara dua aplikasi. Nilai 1 pada diagonal menunjukkan bahwa setiap aplikasi identik dengan dirinya sendiri, sedangkan nilai 0 di luar diagonal berarti aplikasi-aplikasi tersebut tidak memiliki kemiripan berdasarkan fitur TF-IDF yang digunakan."""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=data_selected['App Name'], columns=data_selected['App Name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Kode tersebut membuat sebuah DataFrame cosine_sim_df dari matriks cosine similarity (cosine_sim). Baris dan kolom DataFrame ini menggunakan nama aplikasi (App Name) sebagai indeks dan header kolom, sehingga memudahkan untuk melihat tingkat kemiripan antar aplikasi berdasarkan nama mereka.

Kemudian, dengan menggunakan fungsi .sample(), kode ini menampilkan secara acak 10 baris dan 5 kolom dari matriks similarity tersebut. Hasilnya menunjukkan nilai kemiripan antar aplikasi, di mana angka 1 berarti aplikasi tersebut sangat mirip dengan dirinya sendiri, sedangkan angka 0 berarti tidak ada kemiripan yang terdeteksi pada fitur yang dianalisis.

##**Mendapatkan Rekomendasi**

###Model Content-Based Filtering
"""

def app_recommendations(app_name, similarity_data=cosine_sim_df, items=data_selected[['App Name', 'Category']], k=10):

    # Ambil indeks aplikasi yang paling mirip berdasarkan similarity tertinggi
    index = similarity_data.loc[:, app_name].to_numpy().argpartition(range(-1, -k, -1))

    # Ambil nama-nama aplikasi terdekat dari similarity matrix
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Hapus nama aplikasi input agar tidak direkomendasikan dirinya sendiri
    closest = closest.drop(app_name, errors='ignore')

    # Gabungkan hasil rekomendasi dengan informasi aplikasi
    return pd.DataFrame(closest, columns=['App Name']).merge(items, on='App Name').head(k)

data_selected[data_selected['App Name'].eq('Supermarket Deal Calculator')]

"""**Fungsi: app_recommendations**

Fungsi ini digunakan untuk merekomendasikan aplikasi yang mirip dengan aplikasi tertentu berdasarkan cosine similarity.


app_name: nama aplikasi yang ingin dicari aplikasinya yang mirip.

similarity_data: DataFrame matriks cosine similarity.

items: Data aplikasi (hanya kolom App Name dan Category yang ditampilkan dalam hasil).

k: jumlah rekomendasi (default 10).

Langkah-langkah fungsi:

1. Mencari indeks aplikasi yang paling mirip berdasarkan nilai cosine similarity tertinggi.

2. Mengambil nama-nama aplikasi yang paling dekat (paling mirip).

3. Menghapus nama aplikasi itu sendiri dari daftar rekomendasi (agar tidak merekomendasikan dirinya sendiri).

4. Menggabungkan hasil dengan informasi kategori aplikasi.
"""

for app in ['Supermarket Deal Calculator', 'Happy birth', 'Fire Truck Simulator 3D']:
    print(f'\nRekomendasi untuk {app}:\n')
    print(app_recommendations(app))

"""###**Rekomendasi untuk aplikasi Supermarket Deal Calculator:**

Sistem merekomendasikan beberapa aplikasi lain yang berada dalam kategori Shopping dan memiliki kemiripan fitur dengan Supermarket Deal Calculator. Beberapa aplikasi yang direkomendasikan antara lain Shopping List Barcode Scanner, FidMe Loyalty Cards & Deals at Grocery Supermarkets, hingga Toy Store App. Rekomendasi ini relevan karena memiliki fungsi serupa dalam membantu aktivitas berbelanja dan pengelolaan produk.

###**Rekomendasi untuk aplikasi Happy birth:**

Untuk aplikasi bertema hiburan seperti Happy birth, sistem menghasilkan rekomendasi dari kategori Entertainment seperti LAVA TV, Pelet Online Prank, dan Among us mod MCPE 2021. Aplikasi-aplikasi ini memiliki konten hiburan yang bervariasi, dari video lucu hingga mod game, yang dinilai sesuai dengan selera pengguna aplikasi Happy birth.

###**Rekomendasi untuk aplikasi Fire Truck Simulator 3D:**

Aplikasi ini termasuk dalam kategori Simulation, sehingga sistem memberikan rekomendasi aplikasi simulasi lainnya seperti Car Driving, Armed Air Forces, dan Real Sports Car Game. Aplikasi-aplikasi ini menawarkan pengalaman interaktif dan simulasi kendaraan atau aktivitas serupa yang sesuai dengan konsep dari Fire Truck Simulator 3D.

### Model Popularity-Based Recommendation
"""

def popular_apps(data, n=10):
    return data.sort_values(by=['Installs', 'Rating Count', 'Rating'], ascending=False).head(n)

popular_apps(data_selected)

"""Hasil yang ditampilkan menunjukkan 10 aplikasi yang dianggap paling populer, seperti:

- Contacts dari Google, dengan lebih dari 500 juta pemasangan.

- Книга Вслух. Аудиокниги, aplikasi audiobook dengan rating tinggi (4.9).

- Lose Belly Fat Workouts dan Taiwan Drivers License Test, yang meskipun jumlah installs lebih kecil, tetap masuk karena rating dan jumlah ratingnya tinggi.

Aplikasi-aplikasi ini berasal dari berbagai kategori, menunjukkan bahwa popularitas tidak hanya bergantung pada satu jenis aplikasi, tetapi juga kualitas dan keterlibatan pengguna.
"""



"""# **7. Evaluasi**

### Evaluasi Content-Based Filtering
"""

def diversity_score(recommended, items):
    categories = items.set_index('App Name').loc[recommended]['Category']
    unique_categories = categories.nunique()
    return unique_categories / len(recommended)

def intra_list_similarity(recommended, similarity_matrix):
    # Ambil submatrix cosine similarity antar aplikasi rekomendasi
    sub_sim = similarity_matrix.loc[recommended, recommended]
    # Hitung rata-rata similarity antar semua pasangan berbeda
    n = len(recommended)
    sum_sim = sub_sim.values.sum() - n  # kurangi diagonal (similarity dengan diri sendiri = 1)
    count_pairs = n * (n - 1)
    return sum_sim / count_pairs if count_pairs > 0 else 0

apps_to_test = ['Supermarket Deal Calculator', 'Happy birth', '40 Hadist Peristiwa Akhir Zaman']

print("=== Diversity Score ===")
for app in apps_to_test:
    recommended_apps = app_recommendations(app)['App Name'].tolist()
    div_score = diversity_score(recommended_apps, data_selected)
    print(f"App: {app}")
    print(f" - Diversity Score: {div_score:.3f}")

apps_to_test = ['Supermarket Deal Calculator', 'Happy birth', '40 Hadist Peristiwa Akhir Zaman']

print("\n=== Intra-list Similarity (ILS) ===")
for app in apps_to_test:
    recommended_apps = app_recommendations(app)['App Name'].tolist()
    ils = intra_list_similarity(recommended_apps, cosine_sim_df)
    print(f"App: {app}")
    print(f" - Intra-list Similarity: {ils:.3f}")

"""Dari hasil evaluasi rekomendasi aplikasi untuk beberapa aplikasi contoh, dapat dilihat bahwa nilai Diversity Score untuk aplikasi seperti Supermarket Deal Calculator, Happy birth, dan Fire Truck Simulator 3D adalah sangat rendah, yaitu hanya sekitar 0.1. Artinya, mayoritas aplikasi yang direkomendasikan berada dalam kategori yang sama, sehingga kurang beragam dari segi kategori.

Sementara itu, aplikasi 40 Hadist Peristiwa Akhir Zaman memiliki nilai Diversity Score sedikit lebih tinggi, yaitu 0.2, yang menunjukkan adanya sedikit variasi kategori dalam rekomendasi yang diberikan, meskipun masih relatif rendah.

Nilai Intra-list Similarity untuk semua aplikasi ini adalah sangat tinggi, yaitu 1.0. Hal ini mengindikasikan bahwa aplikasi-aplikasi yang direkomendasikan sangat mirip satu sama lain berdasarkan metrik cosine similarity, sehingga daftar rekomendasi cenderung homogen dan kurang memberikan variasi yang mungkin lebih menarik bagi pengguna.

Secara keseluruhan, hasil ini menunjukkan bahwa sistem rekomendasi saat ini masih memprioritaskan aplikasi dengan kemiripan tinggi dalam kategori yang sama, sehingga perlu adanya upaya untuk meningkatkan keragaman dalam rekomendasi agar pengalaman pengguna menjadi lebih kaya dan beragam.


"""

def precision_at_k(recommend_func, app_name, data, k=10):
    # Ambil kategori asli dari app_name
    true_category = data[data['App Name'] == app_name]['Category'].values
    if len(true_category) == 0:
        return None
    true_category = true_category[0]

    # Ambil rekomendasi aplikasi dari fungsi rekomendasi
    recommendations = recommend_func(app_name)
    recommended_categories = recommendations['Category'].values

    # Hitung berapa banyak aplikasi rekomendasi yang kategori-nya sama dengan app_name
    relevant_count = sum([1 for cat in recommended_categories if cat == true_category])

    # Precision = relevan dibagi jumlah rekomendasi k
    precision = relevant_count / k
    return precision

apps_to_test = ['Supermarket Deal Calculator', 'Happy birth', '40 Hadist Peristiwa Akhir Zaman']
for app in apps_to_test:
    score = precision_at_k(app_recommendations, app, data_selected, k=10)
    print(f"Precision@10 untuk '{app}': {score:.2f}")

"""Hasil evaluasi menggunakan metrik Precision@10 pada beberapa aplikasi menunjukkan nilai 1.00 untuk masing-masing aplikasi: Supermarket Deal Calculator, Happy birth, dan 40 Hadist Peristiwa Akhir Zaman. Ini berarti dari 10 rekomendasi teratas yang diberikan oleh sistem, seluruhnya (100%) termasuk dalam kategori yang sama dengan aplikasi yang dijadikan acuan.

Dengan kata lain, sistem rekomendasi sangat tepat dalam memberikan saran aplikasi yang relevan berdasarkan kategori, sehingga pengguna kemungkinan besar akan menemukan aplikasi yang sesuai dengan minat atau kebutuhan mereka.

Namun, meskipun precision tinggi, perlu diperhatikan bahwa rekomendasi ini bisa saja kurang bervariasi karena semua aplikasi yang direkomendasikan memiliki kategori yang sama.

### Evaluasi Popularity-Based Recommendation
"""

import matplotlib.pyplot as plt
import seaborn as sns

def evaluate_popular_apps(data, n=10):
    # Ambil n aplikasi terpopuler menggunakan fungsi sebelumnya
    popular = popular_apps(data, n)

    # Statistik deskriptif
    print("Statistik Deskriptif 10 Aplikasi Terpopuler:")
    print(popular[['Installs', 'Rating Count', 'Rating']].describe())

    # Konversi 'Installs' ke angka jika masih dalam format string dengan koma atau tanda +
    # Contoh sederhana:
    def convert_installs(x):
        if isinstance(x, str):
            x = x.replace(',', '').replace('+', '')
            return int(x)
        return x

    popular['Installs_numeric'] = popular['Installs'].apply(convert_installs)

    # Plot distribusi metrik
    fig, axs = plt.subplots(1, 3, figsize=(18,5))

    sns.barplot(x='App Name', y='Installs_numeric', data=popular, ax=axs[0])
    axs[0].set_title('Installs (Jumlah Pemasangan)')
    axs[0].tick_params(axis='x', rotation=90)

    sns.barplot(x='App Name', y='Rating Count', data=popular, ax=axs[1])
    axs[1].set_title('Rating Count (Jumlah Rating)')
    axs[1].tick_params(axis='x', rotation=90)

    sns.barplot(x='App Name', y='Rating', data=popular, ax=axs[2])
    axs[2].set_title('Rating (Penilaian)')
    axs[2].tick_params(axis='x', rotation=90)

    plt.tight_layout()
    plt.show()

    # Korelasi antar metrik
    corr = popular[['Installs_numeric', 'Rating Count', 'Rating']].corr()
    print("Korelasi antar metrik:")
    print(corr)

# Panggil fungsi evaluasi
evaluate_popular_apps(data_selected)

"""Dari analisis 10 aplikasi terpopuler berdasarkan jumlah instalasi, rating, dan jumlah rating, didapatkan beberapa informasi penting:

Rating Count (jumlah rating) untuk semua aplikasi adalah konstan, yaitu 427, sehingga tidak ada variasi pada metrik ini.

Rata-rata Rating aplikasi adalah sekitar 4.77 dengan standar deviasi 0.17, menandakan bahwa sebagian besar aplikasi memiliki rating yang cukup tinggi dan relatif konsisten, berkisar antara 4.3 hingga 4.9.

Dari hasil korelasi, terdapat korelasi negatif kuat (-0.97) antara jumlah instalasi dan rating. Ini bisa menunjukkan bahwa aplikasi dengan jumlah instalasi yang sangat besar cenderung memiliki rating sedikit lebih rendah, meskipun perbedaannya kecil.

Karena Rating Count tidak bervariasi (semua sama), korelasi yang melibatkan metrik ini tidak dapat dihitung secara bermakna (ditampilkan sebagai NaN).

Secara keseluruhan, aplikasi terpopuler ini menunjukkan rating yang baik, namun ada indikasi bahwa semakin banyak aplikasi diinstal, rating rata-rata sedikit menurun.
"""